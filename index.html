<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Live Stream</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: #111;
      color: white;
      text-align: center;
      margin: 0; padding: 20px;
    }

    #liveStreamView {
      position: fixed;
      top: 0; left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: contain;
      background: black;
      z-index: 9999;
      display: none;
    }

    #controls {
      margin-bottom: 15px;
      z-index: 10000;
      position: relative;
    }

    button {
      background: #222;
      border: none;
      color: white;
      padding: 10px 15px;
      margin: 0 5px;
      cursor: pointer;
      font-size: 16px;
      border-radius: 5px;
    }

    button:hover {
      background: #555;
    }

    video.preview {
      position: fixed;
      bottom: 10px;
      right: 10px;
      width: 200px;
      z-index: 10001;
      border: 2px solid white;
    }

    #senderVolumeControls {
      position: fixed;
      bottom: 10px;
      right: 220px;
      z-index: 10001;
      background: rgba(0,0,0,0.5);
      padding: 10px;
      border-radius: 8px;
    }

    #senderVolumeControls input[type="range"] {
      width: 100px;
    }
  </style>
</head>
<body>

  <div id="controls">
    <button id="startStreamBtn">Start Streaming (Sender)</button>
    <button id="startReceiveBtn">Start Receiving (Viewer)</button>
    <button id="fullscreenBtn">Full Screen View</button>
    <button id="muteBtn" style="display: none;">Mute Viewer</button>
  </div>

  <div id="senderVolumeControls" style="display: none;">
    <label style="font-size: 14px;">Sender Volume:</label><br>
    <input id="volumeSlider" type="range" min="0" max="1" step="0.01" value="1">
    <button id="senderMuteBtn">Mute</button>
  </div>

  <img id="liveStreamView" alt="Live Stream Here" />

  <script type="module">
    import { initializeApp } from "https://www.gstatic.com/firebasejs/10.3.0/firebase-app.js";
    import { getDatabase, ref, set, onValue } from "https://www.gstatic.com/firebasejs/10.3.0/firebase-database.js";

    const firebaseConfig = {
      apiKey: "AIzaSyCy9CKJ6CELheBhw7Gs0BgsE1E0FsoYdgU",
      authDomain: "project-955237504610034331.firebaseapp.com",
      databaseURL: "https://project-955237504610034331-default-rtdb.firebaseio.com",
      projectId: "project-955237504610034331",
      storageBucket: "project-955237504610034331.appspot.com",
      messagingSenderId: "76212939677",
      appId: "1:76212939677:web:ef498bc1e4e480ab6e5d74",
      measurementId: "G-WXBEP1LXTX"
    };

    const app = initializeApp(firebaseConfig);
    const db = getDatabase(app);
    const videoRef = ref(db, 'liveStream/videoFrame');
    const audioRef = ref(db, 'liveStream/audioChunk');

    let preview;

    async function startStreaming() {
      preview = document.createElement('video');
      preview.autoplay = true;
      preview.muted = false;
      preview.volume = 1;
      preview.className = 'preview';
      document.body.appendChild(preview);

      const volControls = document.getElementById('senderVolumeControls');
      volControls.style.display = 'block';

      let stream;
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        preview.srcObject = stream;
      } catch (err) {
        alert("Camera/Mic access failed: " + err.message);
        return;
      }

      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');

      const audioCtx = new AudioContext();
      const source = audioCtx.createMediaStreamSource(stream);
      const processor = audioCtx.createScriptProcessor(2048, 1, 1);

      processor.onaudioprocess = (e) => {
        const input = e.inputBuffer.getChannelData(0);
        const buffer = new ArrayBuffer(input.length * 2);
        const view = new DataView(buffer);

        for (let i = 0; i < input.length; i++) {
          let s = Math.max(-1, Math.min(1, input[i]));
          s = s < 0 ? s * 0x8000 : s * 0x7FFF;
          view.setInt16(i * 2, s, true);
        }

        const base64Audio = btoa(String.fromCharCode(...new Uint8Array(buffer)));
        set(audioRef, base64Audio);
      };

      source.connect(processor);
      processor.connect(audioCtx.destination);

      const video = document.createElement('video');
      video.srcObject = stream;
      video.play();

      video.onloadedmetadata = () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        setInterval(() => {
          ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
          const frame = canvas.toDataURL('image/jpeg', 0.5);
          set(videoRef, frame);
        }, 100);
      };

      document.getElementById('liveStreamView').style.display = 'block';
    }

    function startReceiving() {
      const img = document.getElementById('liveStreamView');
      const muteBtn = document.getElementById('muteBtn');
      img.style.display = 'block';
      muteBtn.style.display = 'inline-block';

      onValue(videoRef, (snap) => {
        const frame = snap.val();
        if (frame) img.src = frame;
      });

      onValue(audioRef, (snap) => {
        const base64Audio = snap.val();
        if (!base64Audio) return;

        const binary = atob(base64Audio);
        const len = binary.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) bytes[i] = binary.charCodeAt(i);

        if (!window.audioContextReceiver) {
          const audioCtx = new AudioContext();
          const gain = audioCtx.createGain();
          gain.connect(audioCtx.destination);

          window.audioContextReceiver = audioCtx;
          window.audioGainNode = gain;
          window.audioQueue = [];
          window.playing = false;

          muteBtn.onclick = () => {
            gain.gain.value = gain.gain.value > 0 ? 0 : 1;
            muteBtn.textContent = gain.gain.value > 0 ? 'Mute Viewer' : 'Unmute Viewer';
          };
        }

        const ctx = window.audioContextReceiver;
        const float32 = new Float32Array(bytes.length / 2);
        for (let i = 0; i < float32.length; i++) {
          const val = bytes[i * 2] | (bytes[i * 2 + 1] << 8);
          float32[i] = val < 0x8000 ? val / 0x8000 : (val - 0x10000) / 0x8000;
        }

        const buffer = ctx.createBuffer(1, float32.length, 44100);
        buffer.getChannelData(0).set(float32);
        window.audioQueue.push(buffer);

        if (!window.playing) playAudio();

        function playAudio() {
          if (window.audioQueue.length === 0) {
            window.playing = false;
            return;
          }

          const b = window.audioQueue.shift();
          const src = ctx.createBufferSource();
          src.buffer = b;
          src.connect(window.audioGainNode);
          src.start();
          src.onended = playAudio;
          window.playing = true;
        }
      });
    }

    function openFullscreen() {
      const elem = document.getElementById('liveStreamView');
      if (elem.requestFullscreen) {
        elem.requestFullscreen();
      } else if (elem.webkitRequestFullscreen) {
        elem.webkitRequestFullscreen();
      } else if (elem.msRequestFullscreen) {
        elem.msRequestFullscreen();
      }
    }

    document.getElementById('startStreamBtn').onclick = startStreaming;
    document.getElementById('startReceiveBtn').onclick = startReceiving;
    document.getElementById('fullscreenBtn').onclick = openFullscreen;

    document.getElementById('volumeSlider').addEventListener('input', (e) => {
      if (preview) preview.volume = parseFloat(e.target.value);
    });

    document.getElementById('senderMuteBtn').onclick = () => {
      if (preview) {
        preview.muted = !preview.muted;
        document.getElementById('senderMuteBtn').textContent = preview.muted ? 'Unmute' : 'Mute';
      }
    };
  </script>
</body>
</html>
